---
title: "Using DataPackageR"
author: "Greg Finak <gfinak@fredhutch.org>"
date: "`r Sys.Date()`"
output: 
  rmarkdown::html_vignette:
    keep_md: TRUE
vignette: >
  %\VignetteIndexEntry{A Guide to using DataPackageR}
  %\VignetteEngine{knitr::rmarkdown}
  \usepackage[utf8]{inputenc}
  \usepackage{graphicx}
---

```{r, echo = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "",
  eval = TRUE
)
```

# DataPackageR

## Set up a new data package.

We'll set up a new data package based on example in the [README](https://github.com/RGLab/DataPackageR/blob/master/README.md) and provide more detailed information.

```{r }
library(data.tree)
library(DataPackageR)
tmp = normalizePath(tempdir())
processing_code = system.file("extdata","tests","subsetCars.Rmd",package="DataPackageR")
print(processing_code)
setwd(tmp)
DataPackageR::datapackage.skeleton("Test", 
                                   force=TRUE, 
                                   code_files = processing_code, 
                                   r_object_names = "cars_over_20") # cars_over_20 is an R object 
                                                                    # created in the Rmd file.
```

### Package skeleton structure 

This has created a directory, "Test" with the skeleton of a data package.

The `DESCRIPTION` file should be filled out to describe your package. It contains a new `DataVersion` string, and the
revision is automatically incremented if the packaged data changes.

`Read-and-delete-me` has some helpful instructions on how to proceed. 

The `data-raw` directory is where the data cleaning code (`Rmd`) files reside.
The contents of this directory are:

```{r dirstructure,echo=FALSE}
df = data.frame(pathString=file.path("Test",(list.files(tmp,recursive=TRUE))))
as.Node(df)
```

`datapackager.yml` can be edited as necessary to include additional processing scripts (which should be placed in `data-raw`), and raw data should be located under under `/inst/extdata`. It should be copied into that path and the data munging scripts edited to read from there.

### Yaml configuration 

Here are the contents of `datapackager.yml`:

```{r, echo=FALSE}
library(yaml)
setwd(tmp)
cat(as.yaml(yaml.load_file("Test/datapackager.yml")))
```

It includes a `files` property that has an entry for each script, with the `name:` and `enabled:` keys for each file. The `objects` property  lists the data objects produced by the scripts.

The `render_root` property specifies the directory where the Rmd files are rendered. If temporary objects are produced during the processing, they will appear in this directory without polluting the package source tree. A temporary directory is used by default.

### Build your package.

Once your scripts are in place and the data objects are documented, you build the package.
  
To run the build process:

```{r}
# Within the package directory
setwd(tmp)
DataPackageR:::package_build("Test") 
```

### Logging the build process

DataPackageR uses the `futile.logger` pagckage to log progress. If there are errors in the processing, the script will notify you via logging to console and to  `/private/tmp/Test/inst/extdata/Logfiles/processing.log`. Errors should be corrected and the build repeated.

If everything goes smoothly, you will have a new package built in the parent directory. In this case we have a new package 
`Test_1.0.tar.gz`. When the package is installed, it will contain a vignette `subsetCars` that can be loaded using the `vignette()` API. The vignette will detail the processing performed by the `subsetCars.Rmd` processing script. 

### The package source directory after building

```{r, echo=FALSE}
library(yaml)
setwd(tmp)
df = data.frame(pathString=file.path("Test",(list.files("Test",recursive=TRUE))))
as.Node(df)
```

#### Details

A number of things have changed. The subsetCars processing script now appears under `/vignettes` and `inst/doc` as a processed html report so that it will be available to view via `vignette()` once the package is installed. 
`inst/extdata/Logfiles` contains a log file of the entire build process as well as intermediate files created while parsing the R / Rmd code. Documentation Rd files appear in `/man`, these should be edite to provide further details on the data objects in the package. The data objects are stored under `/data` where we see `cars_over_20.rda`, the object we initially specified in `datapackager.yml`.


## Versioning data objects

The DataPackageR package calculates an md5 checksum of each data object it stores, and keeps track of them in a file
called `DATADIGEST`.

- Each time the package is rebuilt, the md5 sums of the new data objects are compared against the DATADIGEST.
- If they don't match, the build process checks that the `DataVersion` string has been incremented in the `DESCRIPTION` file.
- If it has not the build process will exit and produce an error message.

### DATADIGEST


The `DATADIGEST` file contains the following:

```{r, echo=FALSE}
setwd(tmp)
cat(readLines("Test/DATADIGEST"),sep="\n")
```


### DESCRIPTION

The description file has the new `DataVersion` string.

```{r echo=FALSE}
setwd(tmp)
cat(readLines("Test/DESCRIPTION"),sep="\n")
```

### Next steps

Your downstream data analysis can depend on a specific version of your data package (for example by tesing the `packageVersion()` string);

```r{}
if(DataPackageR::packageVersion("MyNewStudy") != "1.0.0")
  stop("The expected version of MyNewStudy is 1.0.0, but ",packageVersion("MyNewStudy")," is installed! Analysis results may differ!")
```

The DataPackageR packge also provides `datasetVersion()` to extract the data set version information. 

You should also place the data package source directory under `git` version control.
This allows you to version control your data processing code. 

### Why not use R CMD build?

If the processing script is time consuming or the data set is particularly large, then `R CMD build` would run the code each time the package is installed. In such cases, raw data may not be available, or the environment to do the data processing may not be set up for each user of the data. In such cases, DataPackageR provides a mechanism to decouple data processing from package building/installation for downstream users of the data.


## Partial builds and migrating old data packages.

Version 1.12.0 has moved away from controlling the build process using `datasets.R` and an additional `masterfile` argument. The build process is now controlled via a `datapackager.yml` configuration file located in the package root directory. 

You can migrate an old package by constructing such a config file using the `construct_yml_config()` API.

```{r  construct_config}
#assume I have file1.Rmd and file2.R located in /data-raw, and these create 'object1' and 'object2' respectively.

config = construct_yml_config(code = c("file1.Rmd","file2.R"), data = c("object1","object2"))
cat(as.yaml(config))
```

`config` is a newly constructed yaml configuration object. It can be written to the package directory:

```{r}
path_to_package = tempdir() #pretend this is the root of our package
yml_write(config,path = path_to_package)
```

Now the package at `path_to_package` will build with version 1.12.0 or greater.

We can also perform partial builds of a subset of files in a package by toggling the `enabled` key in the config file. This can be done with the following API:

```{r}
config = yml_disable_compile(config,filenames = "file2.R")
cat(as.yaml(config))
```

Where `config` is a configuration read from a data package root directory. The `config` object needs to be written back to the package root in order for the changes to take effect. The consequence of toggling a file to `enable: no` is that it will be skipped when the package is built, but the data will be retained, and the documentation will not be altered. 





